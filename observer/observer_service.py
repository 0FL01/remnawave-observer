import os
import json
import logging
import asyncio
from typing import List, Set, Dict
from datetime import datetime
import httpx
import aio_pika
import redis.asyncio as redis
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
RABBITMQ_URL = os.getenv("RABBITMQ_URL", "amqp://guest:guest@localhost/")
MAX_IPS_PER_USER = int(os.getenv("MAX_IPS_PER_USER", 3))
ALERT_WEBHOOK_URL = os.getenv("ALERT_WEBHOOK_URL")
USER_IP_TTL_SECONDS = int(os.getenv("USER_IP_TTL_SECONDS", 24 * 60 * 60))
ALERT_COOLDOWN_SECONDS = int(os.getenv("ALERT_COOLDOWN_SECONDS", 60 * 60))
BLOCK_DURATION = os.getenv("BLOCK_DURATION", "5m")
BLOCKING_EXCHANGE_NAME = "blocking_exchange"
MONITORING_INTERVAL = int(os.getenv("MONITORING_INTERVAL", 300))  # 5 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
excluded_users_str = os.getenv("EXCLUDED_USERS", "")
EXCLUDED_USERS: Set[str] = {email.strip() for email in excluded_users_str.split(',') if email.strip()}

if EXCLUDED_USERS:
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π: {len(EXCLUDED_USERS)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
app = FastAPI(title="Observer Service", version="1.2.1")
redis_client = redis.from_url(REDIS_URL, decode_responses=True)
http_client = httpx.AsyncClient()
rabbitmq_connection = None
blocking_exchange = None
monitoring_task = None

async def monitor_user_ip_pools():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ IP-–ø—É–ª–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π."""
    while True:
        try:
            await asyncio.sleep(MONITORING_INTERVAL)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            pattern = "user_ips:*"
            user_keys = await redis_client.keys(pattern)
            
            if not user_keys:
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] === IP POOLS MONITORING === –ù–ï–¢ –ê–ö–¢–ò–í–ù–´–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô")
                continue
            
            print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] === IP POOLS MONITORING START ===")
            
            total_users = 0
            users_near_limit = 0
            users_over_limit = 0
            
            # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
            user_stats: List[Dict] = []
            
            for key in user_keys:
                try:
                    user_email = key.split(":", 1)[1]
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ IP –∏ TTL
                    async with redis_client.pipeline() as pipe:
                        pipe.scard(key)
                        pipe.ttl(key)
                        pipe.smembers(key)
                        results = await pipe.execute()
                    
                    ip_count = results[0]
                    ttl = results[1]
                    ips = results[2]
                    
                    if ip_count > 0:
                        total_users += 1
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                        status = "NORMAL"
                        if ip_count >= MAX_IPS_PER_USER * 0.8:  # 80% –æ—Ç –ª–∏–º–∏—Ç–∞
                            status = "NEAR_LIMIT"
                            users_near_limit += 1
                        if ip_count > MAX_IPS_PER_USER:
                            status = "OVER_LIMIT"
                            users_over_limit += 1
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω—ã–π –∫—É–ª–¥–∞—É–Ω –Ω–∞ –∞–ª–µ—Ä—Ç—ã
                        alert_cooldown_key = f"alert_sent:{user_email}"
                        has_alert_cooldown = await redis_client.exists(alert_cooldown_key)
                        
                        user_stats.append({
                            'email': user_email,
                            'ip_count': ip_count,
                            'ips': sorted(list(ips)),
                            'ttl_hours': round(ttl / 3600, 1) if ttl > 0 else 0,
                            'status': status,
                            'has_alert_cooldown': bool(has_alert_cooldown),
                            'excluded': user_email in EXCLUDED_USERS
                        })
                
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–ª—é—á–∞ {key}: {e}")
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É IP (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
            user_stats.sort(key=lambda x: x['ip_count'], reverse=True)
            
            # –í—ã–≤–æ–¥–∏–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            print(f"   üë• –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {total_users}")
            print(f"   ‚ö†Ô∏è  –ë–ª–∏–∑–∫–æ –∫ –ª–∏–º–∏—Ç—É ({MAX_IPS_PER_USER}): {users_near_limit}")
            print(f"   üö® –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞: {users_over_limit}")
            print(f"   üõ°Ô∏è  –ò—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len([u for u in user_stats if u['excluded']])}")
            
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-10 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º IP
            print(f"\nüìà –¢–û–ü –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò –ü–û –ö–û–õ–ò–ß–ï–°–¢–í–£ IP:")
            for i, user in enumerate(user_stats[:10], 1):
                status_emoji = {
                    'NORMAL': '‚úÖ',
                    'NEAR_LIMIT': '‚ö†Ô∏è',
                    'OVER_LIMIT': 'üö®'
                }.get(user['status'], '‚ùì')
                
                excluded_marker = ' [EXCLUDED]' if user['excluded'] else ''
                cooldown_marker = ' [ALERT_COOLDOWN]' if user['has_alert_cooldown'] else ''
                
                print(f"   {i:2d}. {status_emoji} {user['email']}{excluded_marker}{cooldown_marker}")
                print(f"       IP: {user['ip_count']}/{MAX_IPS_PER_USER} | TTL: {user['ttl_hours']}h")
                print(f"       IPs: {', '.join(user['ips'])}")
            
            # –û—Ç–¥–µ–ª—å–Ω–æ –≤—ã–≤–æ–¥–∏–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ–º –ª–∏–º–∏—Ç–∞
            over_limit_users = [u for u in user_stats if u['status'] == 'OVER_LIMIT']
            if over_limit_users:
                print(f"\nüö® –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò –° –ü–†–ï–í–´–®–ï–ù–ò–ï–ú –õ–ò–ú–ò–¢–ê:")
                for user in over_limit_users:
                    excluded_marker = ' [EXCLUDED - –ù–ï –ë–õ–û–ö–ò–†–£–ï–¢–°–Ø]' if user['excluded'] else ''
                    cooldown_marker = ' [ALERT_COOLDOWN]' if user['has_alert_cooldown'] else ''
                    print(f"   ‚Ä¢ {user['email']}{excluded_marker}{cooldown_marker}")
                    print(f"     IP: {user['ip_count']}/{MAX_IPS_PER_USER} | TTL: {user['ttl_hours']}h")
                    print(f"     IPs: {', '.join(user['ips'])}")
            
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] === IP POOLS MONITORING END ===\n")
            
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ IP-–ø—É–ª–æ–≤: {e}")
            await asyncio.sleep(30)  # –ö–æ—Ä–æ—Ç–∫–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π

@app.on_event("startup")
async def startup_event():
    """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ –∏ –∑–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    global rabbitmq_connection, blocking_exchange, monitoring_task
    try:
        rabbitmq_connection = await aio_pika.connect_robust(RABBITMQ_URL)
        channel = await rabbitmq_connection.channel()
        blocking_exchange = await channel.declare_exchange(
            BLOCKING_EXCHANGE_NAME, aio_pika.ExchangeType.FANOUT, durable=True
        )
        logger.info("–£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ.")
    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ RabbitMQ: {e}")
        rabbitmq_connection = None
    
    # –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ IP-–ø—É–ª–æ–≤
    monitoring_task = asyncio.create_task(monitor_user_ip_pools())
    logger.info(f"–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ IP-–ø—É–ª–æ–≤ –∑–∞–ø—É—â–µ–Ω —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º {MONITORING_INTERVAL} —Å–µ–∫—É–Ω–¥.")

@app.on_event("shutdown")
async def shutdown_event():
    """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π."""
    global monitoring_task
    
    # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    if monitoring_task:
        monitoring_task.cancel()
        try:
            await monitoring_task
        except asyncio.CancelledError:
            pass
        logger.info("–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ IP-–ø—É–ª–æ–≤ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
    
    if rabbitmq_connection:
        await rabbitmq_connection.close()
    await http_client.aclose()
    await redis_client.aclose()
    logger.info("–í—Å–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–∫—Ä—ã—Ç—ã.")

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class LogEntry(BaseModel):
    user_email: str = Field(..., alias="user_email")
    source_ip: str = Field(..., alias="source_ip")

class AlertPayload(BaseModel):
    user_identifier: str
    detected_ips_count: int
    limit: int
    violation_type: str = "ip_limit_exceeded"

@app.post("/log-entry")
async def process_log_entries(entries: List[LogEntry]):
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–æ–≥–æ–≤."""
    for entry in entries:
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Å–ø–∏—Å–∫–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
            if entry.user_email in EXCLUDED_USERS:
                continue

            user_ips_key = f"user_ips:{entry.user_email}"
            alert_sent_key = f"alert_sent:{entry.user_email}"

            async with redis_client.pipeline() as pipe:
                pipe.sadd(user_ips_key, entry.source_ip)
                pipe.expire(user_ips_key, USER_IP_TTL_SECONDS)
                pipe.scard(user_ips_key)
                pipe.exists(alert_sent_key)
                results = await pipe.execute()

            current_ip_count = results[2]
            alert_was_sent = bool(results[3])

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫—É–ª–¥–∞—É–Ω–∞
            if current_ip_count > MAX_IPS_PER_USER and not alert_was_sent:
                logger.warning(f"–ü–†–ï–í–´–®–ï–ù–ò–ï –õ–ò–ú–ò–¢–ê: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {entry.user_email}, IP-–∞–¥—Ä–µ—Å–æ–≤: {current_ip_count}/{MAX_IPS_PER_USER}.")
                
                all_user_ips = await redis_client.smembers(user_ips_key)
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ –∫–æ–º–∞–Ω–¥—ã –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É —á–µ—Ä–µ–∑ RabbitMQ
                if blocking_exchange and all_user_ips:
                    block_message_body = {"ips": list(all_user_ips), "duration": BLOCK_DURATION}
                    message = aio_pika.Message(
                        body=json.dumps(block_message_body).encode(),
                        delivery_mode=aio_pika.DeliveryMode.PERSISTENT
                    )
                    await blocking_exchange.publish(message, routing_key="")
                    logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ –¥–ª—è {entry.user_email} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.")
                
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫—É–ª–¥–∞—É–Ω–∞ –Ω–∞ –∞–ª–µ—Ä—Ç—ã –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                await redis_client.setex(alert_sent_key, ALERT_COOLDOWN_SECONDS, "1")
                if ALERT_WEBHOOK_URL:
                    alert_payload = AlertPayload(
                        user_identifier=entry.user_email,
                        detected_ips_count=current_ip_count,
                        limit=MAX_IPS_PER_USER,
                    )
                    try:
                        await http_client.post(ALERT_WEBHOOK_URL, json=alert_payload.dict(), timeout=10.0)
                    except httpx.RequestError as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞–ª–µ—Ä—Ç–∞ –¥–ª—è {entry.user_email}: {e}")

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è {entry.user_email}: {e}")

    return {"status": "ok", "processed_entries": len(entries)}

@app.get("/health")
async def health_check():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞."""
    try:
        await redis_client.ping()
        return {"status": "ok", "redis_connection": "ok"}
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Redis connection failed: {e}")

@app.get("/user-ip-stats")
async def get_user_ip_stats():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ IP-–ø—É–ª–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏."""
    try:
        pattern = "user_ips:*"
        user_keys = await redis_client.keys(pattern)
        
        if not user_keys:
            return {"total_users": 0, "users": []}
        
        user_stats = []
        
        for key in user_keys:
            try:
                user_email = key.split(":", 1)[1]
                
                async with redis_client.pipeline() as pipe:
                    pipe.scard(key)
                    pipe.ttl(key)
                    pipe.smembers(key)
                    results = await pipe.execute()
                
                ip_count = results[0]
                ttl = results[1]
                ips = results[2]
                
                if ip_count > 0:
                    alert_cooldown_key = f"alert_sent:{user_email}"
                    has_alert_cooldown = await redis_client.exists(alert_cooldown_key)
                    
                    user_stats.append({
                        'email': user_email,
                        'ip_count': ip_count,
                        'ips': sorted(list(ips)),
                        'ttl_seconds': ttl if ttl > 0 else 0,
                        'over_limit': ip_count > MAX_IPS_PER_USER,
                        'has_alert_cooldown': bool(has_alert_cooldown),
                        'excluded': user_email in EXCLUDED_USERS
                    })
            
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–ª—é—á–∞ {key}: {e}")
        
        user_stats.sort(key=lambda x: x['ip_count'], reverse=True)
        
        return {
            "total_users": len(user_stats),
            "users_over_limit": len([u for u in user_stats if u['over_limit']]),
            "monitoring_interval": MONITORING_INTERVAL,
            "max_ips_per_user": MAX_IPS_PER_USER,
            "users": user_stats
        }
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ IP-–ø—É–ª–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get IP stats: {e}")